{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KDxGyzDcO8EJ"
      },
      "outputs": [],
      "source": [
        "!pip install git+https://github.com/huggingface/diffusers.git transformers accelerate xformers==0.0.16 datasets==2.21.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import gradio as gr\n",
        "import torch\n",
        "import torchvision.transforms as T\n",
        "from diffusers import StableDiffusionControlNetPipeline, ControlNetModel\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "# -------- CONFIG --------\n",
        "CONTROLNET_REPO = \"swetha3456/thermal-rgb-controlnet-v2\"\n",
        "SUBFOLDER = \"sketch2webpage_synthetic_checkpoint-4000/controlnet\"\n",
        "BASE_MODEL = \"stable-diffusion-v1-5/stable-diffusion-v1-5\"\n",
        "RESOLUTION = 384\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "DTYPE = torch.float16 if DEVICE == \"cuda\" else torch.float32\n",
        "# ------------------------\n",
        "\n",
        "# ControlNet\n",
        "controlnet = ControlNetModel.from_pretrained(\n",
        "    CONTROLNET_REPO,\n",
        "    subfolder=SUBFOLDER,\n",
        "    torch_dtype=DTYPE\n",
        ")\n",
        "\n",
        "# Pipeline\n",
        "pipe = StableDiffusionControlNetPipeline.from_pretrained(\n",
        "    BASE_MODEL,\n",
        "    controlnet=controlnet,\n",
        "    torch_dtype=DTYPE,\n",
        "    safety_checker=None\n",
        ").to(DEVICE)\n",
        "\n",
        "pipe.enable_xformers_memory_efficient_attention()\n",
        "\n",
        "# EXACT training-time conditioning transform\n",
        "cond_transform = T.Compose([\n",
        "    T.Resize(RESOLUTION),\n",
        "    T.CenterCrop(RESOLUTION),\n",
        "    T.ToTensor(),   # [0,1], no normalization\n",
        "])\n",
        "\n",
        "def thermal_to_rgb(thermal_img, prompt=\"\"):\n",
        "    if thermal_img is None:\n",
        "        return None\n",
        "\n",
        "    if isinstance(thermal_img, np.ndarray):\n",
        "        thermal_img = Image.fromarray(thermal_img)\n",
        "\n",
        "    thermal_img = thermal_img.convert(\"RGB\")\n",
        "\n",
        "    control = cond_transform(thermal_img).unsqueeze(0).to(\n",
        "        device=DEVICE,\n",
        "        dtype=DTYPE\n",
        "    )\n",
        "\n",
        "    # if not prompt or prompt.strip() == \"\":\n",
        "    #     prompt = \"a realistic RGB photo\"\n",
        "\n",
        "    result = pipe(\n",
        "        prompt=prompt,\n",
        "        image=control,\n",
        "        num_inference_steps=20,\n",
        "        guidance_scale=7.5,\n",
        "        controlnet_conditioning_scale=1.0\n",
        "    )\n",
        "\n",
        "    return result.images[0]\n",
        "\n",
        "# -------- GRADIO UI --------\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"## Skecth â†’ Webpage Generation\")\n",
        "\n",
        "    with gr.Row():\n",
        "        inp = gr.Image(\n",
        "            label=\"Sketch\",\n",
        "            type=\"numpy\",\n",
        "            value=\"../dataset_sketch2webpage/10018_0.jpeg\"  # must exist\n",
        "        )\n",
        "        out = gr.Image(label=\"Generated Webpage from Sketch\")\n",
        "\n",
        "    # prompt_inp = gr.Textbox(\n",
        "    #     label=\"Prompt\",\n",
        "    #     value=\"road scene with trees electric poles and cables\"\n",
        "    # )\n",
        "\n",
        "    btn = gr.Button(\"Generate Webpage\")\n",
        "    btn.click(\n",
        "        fn=thermal_to_rgb,\n",
        "        inputs=[inp, prompt_inp],\n",
        "        outputs=out\n",
        "    )\n",
        "\n",
        "demo.launch()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
